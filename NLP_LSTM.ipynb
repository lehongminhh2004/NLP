{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lehongminhh2004/NLP/blob/main/NLP_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdYFY3FktIJQ"
      },
      "source": [
        "# D·ªäCH M√ÅY ANH‚ÄìPH√ÅP / V·ªöI M√î H√åNH ENCODER‚ÄìDECODER LSTM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDc0RDrytUXy"
      },
      "source": [
        "## 1. C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz-IrJqDtfOk",
        "outputId": "bcc634ae-cc55-477c-c1aa-08296e8c1dd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing dependencies...\n",
            "================================================================================\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "‚úì en_core_web_sm already available\n",
            "\n",
            "‚úÖ Setup completed!\n",
            "üñ•Ô∏è  Device: cuda\n",
            "üéÆ GPU: Tesla T4\n",
            "üíæ Memory: 15.83 GB\n"
          ]
        }
      ],
      "source": [
        "print(\"Installing dependencies...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "!pip -q install spacy\n",
        "\n",
        "# C√†i model FR (nh∆∞ c≈©)\n",
        "!python -m spacy download fr_core_news_sm -q\n",
        "\n",
        "# C√†i model EN: th·ª≠ download chu·∫©n, n·∫øu fail th√¨ pip install wheel tr·ª±c ti·∫øp\n",
        "try:\n",
        "    import spacy\n",
        "    spacy.load(\"en_core_web_sm\")\n",
        "    print(\"‚úì en_core_web_sm already available\")\n",
        "except Exception:\n",
        "    try:\n",
        "        !python -m spacy download en_core_web_sm -q\n",
        "        print(\"‚úì en_core_web_sm downloaded via spacy\")\n",
        "    except Exception:\n",
        "        !pip -q install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl\n",
        "        print(\"‚úì en_core_web_sm installed via direct wheel\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import spacy\n",
        "import random, math, time\n",
        "import requests, gzip, io\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"\\n‚úÖ Setup completed!\")\n",
        "print(f\"üñ•Ô∏è  Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üíæ Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VbAu1WguKf4"
      },
      "source": [
        "## 2. T·∫£i MULTI30K Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qeNBflMwtgMY",
        "outputId": "85cda332-4bba-4f01-cc36-ceb7345a002c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "T·∫¢I MULTI30K (EN‚ÄìFR)\n",
            "================================================================================\n",
            "Downloading .gz files:\n",
            "  ‚úì train.en.gz: 29000\n",
            "  ‚úì train.fr.gz: 29000\n",
            "  ‚úì val.en.gz: 1014\n",
            "  ‚úì val.fr.gz: 1014\n",
            "  ‚úì test_2016_flickr.en.gz: 1000\n",
            "  ‚úì test_2016_flickr.fr.gz: 1000\n",
            "\n",
            "üìä Dataset Statistics:\n",
            "  ‚Ä¢ Train: 29,000\n",
            "  ‚Ä¢ Val:   1,014\n",
            "  ‚Ä¢ Test:  1,000\n",
            "\n",
            "üìù Samples:\n",
            "\n",
            "[1] EN: Two young, White males are outside near many bushes.\n",
            "    FR: Deux jeunes hommes blancs sont dehors pr√®s de buissons.\n",
            "\n",
            "[2] EN: Several men in hard hats are operating a giant pulley system.\n",
            "    FR: Plusieurs hommes en casque font fonctionner un syst√®me de poulies g√©ant.\n",
            "\n",
            "[3] EN: A little girl climbing into a wooden playhouse.\n",
            "    FR: Une petite fille grimpe dans une maisonnette en bois.\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"T·∫¢I MULTI30K (EN‚ÄìFR)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "import gzip\n",
        "import io\n",
        "import requests\n",
        "\n",
        "BASE_URL = \"https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/\"\n",
        "\n",
        "FILES_GZ = {\n",
        "    \"train.en\": \"train.en.gz\",\n",
        "    \"train.fr\": \"train.fr.gz\",\n",
        "    \"val.en\":   \"val.en.gz\",\n",
        "    \"val.fr\":   \"val.fr.gz\",\n",
        "    \"test.en\":  \"test_2016_flickr.en.gz\",\n",
        "    \"test.fr\":  \"test_2016_flickr.fr.gz\",\n",
        "}\n",
        "\n",
        "FILES_PLAIN = {\n",
        "    \"train.en\": \"train.en\",\n",
        "    \"train.fr\": \"train.fr\",\n",
        "    \"val.en\":   \"val.en\",\n",
        "    \"val.fr\":   \"val.fr\",\n",
        "    \"test.en\":  \"test_2016_flickr.en\",\n",
        "    \"test.fr\":  \"test_2016_flickr.fr\",\n",
        "}\n",
        "\n",
        "def _download_text(url: str, timeout: int = 60) -> str:\n",
        "    r = requests.get(url, timeout=timeout)\n",
        "    r.raise_for_status()\n",
        "    return r.text\n",
        "\n",
        "def _download_gz_lines(url: str, timeout: int = 60) -> list[str]:\n",
        "    r = requests.get(url, timeout=timeout)\n",
        "    r.raise_for_status()\n",
        "    with gzip.open(io.BytesIO(r.content), \"rt\", encoding=\"utf-8\") as f:\n",
        "        return f.read().splitlines()\n",
        "\n",
        "def download_multi30k():\n",
        "    data = {}\n",
        "\n",
        "    print(\"Downloading .gz files:\")\n",
        "    for key, fname in FILES_GZ.items():\n",
        "        url = BASE_URL + fname\n",
        "        try:\n",
        "            lines = _download_gz_lines(url)\n",
        "            data[key] = lines\n",
        "            print(f\"  ‚úì {fname}: {len(lines)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚úó {fname}: {type(e).__name__}\")\n",
        "\n",
        "    # fallback n·∫øu thi·∫øu file n√†o ƒë√≥\n",
        "    missing = [k for k in FILES_GZ.keys() if k not in data]\n",
        "    if missing:\n",
        "        print(\"\\nFallback to plain text for missing files:\")\n",
        "        for key in missing:\n",
        "            fname = FILES_PLAIN[key]\n",
        "            url = BASE_URL + fname\n",
        "            try:\n",
        "                text = _download_text(url)\n",
        "                lines = text.splitlines()\n",
        "                data[key] = lines\n",
        "                print(f\"  ‚úì {fname}: {len(lines)}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚úó {fname}: {type(e).__name__}\")\n",
        "\n",
        "    # sanity check\n",
        "    n_train = len(data.get(\"train.en\", []))\n",
        "    n_val   = len(data.get(\"val.en\", []))\n",
        "    n_test  = len(data.get(\"test.en\", []))\n",
        "\n",
        "    print(\"\\nüìä Dataset Statistics:\")\n",
        "    print(f\"  ‚Ä¢ Train: {n_train:,}\")\n",
        "    print(f\"  ‚Ä¢ Val:   {n_val:,}\")\n",
        "    print(f\"  ‚Ä¢ Test:  {n_test:,}\")\n",
        "\n",
        "    if n_train < 1000:\n",
        "        raise RuntimeError(\"Dataset seems incomplete (train.en < 1000). Check download URLs/connectivity.\")\n",
        "\n",
        "    # sample\n",
        "    print(\"\\nüìù Samples:\")\n",
        "    for i in range(min(3, n_train)):\n",
        "        en = data[\"train.en\"][i]\n",
        "        fr = data[\"train.fr\"][i]\n",
        "        print(f\"\\n[{i+1}] EN: {en[:200] + ('...' if len(en) > 200 else '')}\")\n",
        "        print(f\"    FR: {fr[:200] + ('...' if len(fr) > 200 else '')}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "raw_data = download_multi30k()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uruYJ4C9ztJ1"
      },
      "source": [
        "## 3. TOKENIZATION V·ªöI SPACY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAneJix0zxM3",
        "outputId": "b318aaf3-41cb-4962-dfb7-6f1db88b1fce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "TOKENIZE v·ªõi SPACY\n",
            "================================================================================\n",
            "Loading spaCy models...\n",
            "  ‚úì en_core_web_sm\n",
            "  ‚úì fr_core_news_sm\n",
            "\n",
            "Tokenizing datasets...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train EN: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29000/29000 [00:01<00:00, 23211.94it/s]\n",
            "Train FR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29000/29000 [00:01<00:00, 18130.14it/s]\n",
            "Val EN: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1014/1014 [00:00<00:00, 31491.29it/s]\n",
            "Val FR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1014/1014 [00:00<00:00, 21963.22it/s]\n",
            "Test EN: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 34418.19it/s]\n",
            "Test FR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 22886.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìå Tokenization example:\n",
            "EN raw : Two young, White males are outside near many bushes.\n",
            "EN tok : ['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']\n",
            "FR raw : Deux jeunes hommes blancs sont dehors pr√®s de buissons.\n",
            "FR tok : ['deux', 'jeunes', 'hommes', 'blancs', 'sont', 'dehors', 'pr√®s', 'de', 'buissons', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TOKENIZE v·ªõi SPACY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# y√™u c·∫ßu: ƒë√£ c√≥ raw_data t·ª´ b∆∞·ªõc t·∫£i dataset\n",
        "import spacy\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"Loading spaCy models...\")\n",
        "spacy_en = spacy.load(\"en_core_web_sm\")\n",
        "spacy_fr = spacy.load(\"fr_core_news_sm\")\n",
        "print(\"  ‚úì en_core_web_sm\")\n",
        "print(\"  ‚úì fr_core_news_sm\")\n",
        "\n",
        "def preprocess_text(text: str) -> str:\n",
        "    # normalize whitespace + lowercase, gi·ªØ d·∫•u c√¢u & accents\n",
        "    return \" \".join(text.split()).lower()\n",
        "\n",
        "def tokenize_en(text: str) -> list[str]:\n",
        "    text = preprocess_text(text)\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "def tokenize_fr(text: str) -> list[str]:\n",
        "    text = preprocess_text(text)\n",
        "    return [tok.text for tok in spacy_fr.tokenizer(text)]\n",
        "\n",
        "print(\"\\nTokenizing datasets...\")\n",
        "train_en = [tokenize_en(s) for s in tqdm(raw_data[\"train.en\"], desc=\"Train EN\")]\n",
        "train_fr = [tokenize_fr(s) for s in tqdm(raw_data[\"train.fr\"], desc=\"Train FR\")]\n",
        "val_en   = [tokenize_en(s) for s in tqdm(raw_data[\"val.en\"],   desc=\"Val EN\")]\n",
        "val_fr   = [tokenize_fr(s) for s in tqdm(raw_data[\"val.fr\"],   desc=\"Val FR\")]\n",
        "test_en  = [tokenize_en(s) for s in tqdm(raw_data[\"test.en\"],  desc=\"Test EN\")]\n",
        "test_fr  = [tokenize_fr(s) for s in tqdm(raw_data[\"test.fr\"],  desc=\"Test FR\")]\n",
        "\n",
        "print(\"\\nüìå Tokenization example:\")\n",
        "print(\"EN raw :\", raw_data[\"train.en\"][0])\n",
        "print(\"EN tok :\", train_en[0])\n",
        "print(\"FR raw :\", raw_data[\"train.fr\"][0])\n",
        "print(\"FR tok :\", train_fr[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9b1pkzfGOv9"
      },
      "source": [
        "## 4. X√¢y d·ª±ng Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBrADYs0GZcS",
        "outputId": "e7e9a1e2-079c-494d-f2ee-a144155c246e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "X√ÇY D·ª∞NG VOCABULARY\n",
            "================================================================================\n",
            "Building vocabularies...\n",
            "\n",
            "üìä Vocabulary Statistics:\n",
            "  ‚Ä¢ English vocab size: 5,892\n",
            "  ‚Ä¢ French vocab size:  6,470\n",
            "\n",
            "üè∑Ô∏è  Special Tokens (EN vocab):\n",
            "  ‚Ä¢ <pad>: 0\n",
            "  ‚Ä¢ <sos>: 1\n",
            "  ‚Ä¢ <eos>: 2\n",
            "  ‚Ä¢ <unk>: 3\n",
            "\n",
            "üìù Numericalization Example:\n",
            "  Tokens:  ['two', 'young', ',', 'white', 'males']\n",
            "  Indices: [16, 24, 15, 25, 774]\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"X√ÇY D·ª∞NG VOCABULARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "class Vocabulary:\n",
        "    \"\"\"\n",
        "    Vocabulary cho seq2seq:\n",
        "      - Build t·ª´ train set\n",
        "      - Gi·ªØ token c√≥ freq >= freq_threshold\n",
        "      - Gi·ªõi h·∫°n top_k ph·ªï bi·∫øn nh·∫•t\n",
        "      - Special tokens: <pad>, <sos>, <eos>, <unk>\n",
        "    \"\"\"\n",
        "    def __init__(self, freq_threshold=2, top_k=10000):\n",
        "        self.itos = {0: \"<pad>\", 1: \"<sos>\", 2: \"<eos>\", 3: \"<unk>\"}\n",
        "        self.stoi = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3}\n",
        "        self.freq_threshold = freq_threshold\n",
        "        self.top_k = top_k\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.itos)\n",
        "\n",
        "    def build_vocabulary(self, sentence_list):\n",
        "        frequencies = Counter()\n",
        "        for sentence in sentence_list:\n",
        "            frequencies.update(sentence)\n",
        "\n",
        "        idx = 4\n",
        "        for word, count in frequencies.most_common(self.top_k):\n",
        "            if count >= self.freq_threshold:\n",
        "                self.stoi[word] = idx\n",
        "                self.itos[idx] = word\n",
        "                idx += 1\n",
        "\n",
        "    def numericalize(self, tokens):\n",
        "        unk = self.stoi[\"<unk>\"]\n",
        "        return [self.stoi.get(tok, unk) for tok in tokens]\n",
        "\n",
        "\n",
        "print(\"Building vocabularies...\")\n",
        "en_vocab = Vocabulary(freq_threshold=2, top_k=10000)\n",
        "fr_vocab = Vocabulary(freq_threshold=2, top_k=10000)\n",
        "\n",
        "en_vocab.build_vocabulary(train_en)\n",
        "fr_vocab.build_vocabulary(train_fr)\n",
        "\n",
        "print(\"\\nüìä Vocabulary Statistics:\")\n",
        "print(f\"  ‚Ä¢ English vocab size: {len(en_vocab):,}\")\n",
        "print(f\"  ‚Ä¢ French vocab size:  {len(fr_vocab):,}\")\n",
        "\n",
        "print(\"\\nüè∑Ô∏è  Special Tokens (EN vocab):\")\n",
        "print(f\"  ‚Ä¢ <pad>: {en_vocab.stoi['<pad>']}\")\n",
        "print(f\"  ‚Ä¢ <sos>: {en_vocab.stoi['<sos>']}\")\n",
        "print(f\"  ‚Ä¢ <eos>: {en_vocab.stoi['<eos>']}\")\n",
        "print(f\"  ‚Ä¢ <unk>: {en_vocab.stoi['<unk>']}\")\n",
        "\n",
        "example = train_en[0][:5]\n",
        "print(\"\\nüìù Numericalization Example:\")\n",
        "print(f\"  Tokens:  {example}\")\n",
        "print(f\"  Indices: {en_vocab.numericalize(example)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnN2BCP8I0NW"
      },
      "source": [
        "## 5. Dataset v√† Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBS4GA-SI48f",
        "outputId": "b1b0face-ec3e-4f4f-94ff-73bd56c5c043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "DATASET & DATALOADER\n",
            "================================================================================\n",
            "‚úÖ Dataloaders created!\n",
            "  ‚Ä¢ Batch size: 64\n",
            "  ‚Ä¢ Train batches: 454\n",
            "  ‚Ä¢ Val batches:   16\n",
            "  ‚Ä¢ Test batches:  16\n",
            "\n",
            "üìä Sample shapes:\n",
            "  ‚Ä¢ src: torch.Size([64, 29])\n",
            "  ‚Ä¢ src_lengths: torch.Size([64]) (min=8, max=29)\n",
            "  ‚Ä¢ trg: torch.Size([64, 38])\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DATASET & DATALOADER\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Tr·∫£ v·ªÅ (src_ids, trg_ids) d·∫°ng tensor 1D.\n",
        "    trg_ids c√≥ th√™m <sos> ·ªü ƒë·∫ßu v√† <eos> ·ªü cu·ªëi.\n",
        "    \"\"\"\n",
        "    def __init__(self, src_data, trg_data, src_vocab, trg_vocab):\n",
        "        self.src_data = src_data\n",
        "        self.trg_data = trg_data\n",
        "        self.src_vocab = src_vocab\n",
        "        self.trg_vocab = trg_vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_tokens = self.src_data[idx]\n",
        "        trg_tokens = self.trg_data[idx]\n",
        "\n",
        "        src_ids = self.src_vocab.numericalize(src_tokens)\n",
        "        trg_ids = (\n",
        "            [self.trg_vocab.stoi[\"<sos>\"]]\n",
        "            + self.trg_vocab.numericalize(trg_tokens)\n",
        "            + [self.trg_vocab.stoi[\"<eos>\"]]\n",
        "        )\n",
        "\n",
        "        return torch.tensor(src_ids, dtype=torch.long), torch.tensor(trg_ids, dtype=torch.long)\n",
        "\n",
        "\n",
        "def collate_fn(batch, pad_idx=0):\n",
        "    \"\"\"\n",
        "    batch: list[(src_1d, trg_1d)]\n",
        "    return:\n",
        "      src_batch: [B, src_len]\n",
        "      src_lengths: [B] (ƒë√£ sort gi·∫£m d·∫ßn)\n",
        "      trg_batch: [B, trg_len] (ƒë√£ sort theo src)\n",
        "    \"\"\"\n",
        "    src_list, trg_list = zip(*batch)\n",
        "\n",
        "    src_lengths = torch.tensor([len(s) for s in src_list], dtype=torch.long)\n",
        "\n",
        "    src_batch = pad_sequence(src_list, batch_first=True, padding_value=pad_idx)\n",
        "    trg_batch = pad_sequence(trg_list, batch_first=True, padding_value=pad_idx)\n",
        "\n",
        "    src_lengths, sort_idx = src_lengths.sort(descending=True)\n",
        "    src_batch = src_batch[sort_idx]\n",
        "    trg_batch = trg_batch[sort_idx]\n",
        "\n",
        "    return src_batch, src_lengths, trg_batch\n",
        "\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataset = TranslationDataset(train_en, train_fr, en_vocab, fr_vocab)\n",
        "val_dataset   = TranslationDataset(val_en,   val_fr,   en_vocab, fr_vocab)\n",
        "test_dataset  = TranslationDataset(test_en,  test_fr,  en_vocab, fr_vocab)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  collate_fn=collate_fn)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "print(\"‚úÖ Dataloaders created!\")\n",
        "print(f\"  ‚Ä¢ Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  ‚Ä¢ Train batches: {len(train_loader)}\")\n",
        "print(f\"  ‚Ä¢ Val batches:   {len(val_loader)}\")\n",
        "print(f\"  ‚Ä¢ Test batches:  {len(test_loader)}\")\n",
        "\n",
        "src_sample, src_len_sample, trg_sample = next(iter(train_loader))\n",
        "print(\"\\nüìä Sample shapes:\")\n",
        "print(f\"  ‚Ä¢ src: {src_sample.shape}\")\n",
        "print(f\"  ‚Ä¢ src_lengths: {src_len_sample.shape} (min={src_len_sample.min().item()}, max={src_len_sample.max().item()})\")\n",
        "print(f\"  ‚Ä¢ trg: {trg_sample.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sway-cSxK2Oz"
      },
      "source": [
        "## 6. Model\n",
        "### 6.1 Encoder Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUzc5UPlK42u",
        "outputId": "0f5254a6-5332-4baf-edb5-4169f819034b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ENCODER (LSTM + PACK)\n",
            "================================================================================\n",
            "‚úÖ Encoder class defined!\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ENCODER (LSTM + PACK)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    LSTM Encoder: nh·∫≠n src ƒë√£ padding + src_lengths (ƒë√£ sort gi·∫£m d·∫ßn),\n",
        "    d√πng pack_padded_sequence ƒë·ªÉ b·ªè ph·∫ßn <pad> khi ch·∫°y LSTM.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, dropout, pad_idx=0):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=pad_idx)\n",
        "        self.lstm = nn.LSTM(\n",
        "            emb_dim, hidden_dim, n_layers,\n",
        "            dropout=dropout if n_layers > 1 else 0,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_lengths):\n",
        "        # src: [B, src_len], src_lengths: [B] (sorted desc)\n",
        "        embedded = self.dropout(self.embedding(src))  # [B, src_len, emb_dim]\n",
        "\n",
        "        packed = pack_padded_sequence(\n",
        "            embedded,\n",
        "            lengths=src_lengths.cpu(),\n",
        "            batch_first=True,\n",
        "            enforce_sorted=True\n",
        "        )\n",
        "\n",
        "        _, (hidden, cell) = self.lstm(packed)\n",
        "        return hidden, cell\n",
        "\n",
        "print(\"‚úÖ Encoder class defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIwuYD_6LD5k"
      },
      "source": [
        "### 6.2 Decoder Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP7IpaELLGGl",
        "outputId": "be3a8f30-b8a9-456e-8d13-c2928ea85dbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " DECODER\n",
            "================================================================================\n",
            "‚úÖ Decoder class defined!\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" DECODER\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers, dropout, pad_idx=0):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=pad_idx)\n",
        "        self.lstm = nn.LSTM(\n",
        "            emb_dim, hidden_dim, n_layers,\n",
        "            dropout=dropout if n_layers > 1 else 0,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, cell, teacher_forcing_ratio=0.5):\n",
        "        input = input.unsqueeze(1)  # [B] -> [B, 1]\n",
        "        embedded = self.dropout(self.embedding(input))  # [B, 1, emb_dim]\n",
        "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))  # output: [B, 1, hidden_dim]\n",
        "        prediction = self.fc_out(output.squeeze(1))  # [B, output_dim]\n",
        "\n",
        "        # Teacher Forcing: ch·ªçn token ti·∫øp theo d·ª±a tr√™n ground truth ho·∫∑c predicted token\n",
        "        teacher_force = random.random() < teacher_forcing_ratio\n",
        "        top1 = prediction.argmax(1)  # [B]\n",
        "        input = trg[:, t] if teacher_force else top1\n",
        "\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "\n",
        "print(\"‚úÖ Decoder class defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyfgqXV6Li-6"
      },
      "source": [
        "### 6.3 Seq2Seq Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Rb2padRMAlX",
        "outputId": "6c754a31-1bed-49f1-e19c-c05c118235df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "K·∫æT H·ª¢P ENCODER-DECODER\n",
            "================================================================================\n",
            "‚úÖ Seq2Seq model initialized!\n",
            "  ‚Ä¢ Total parameters: 13,840,198\n",
            "  ‚Ä¢ Encoder params:   5,186,560\n",
            "  ‚Ä¢ Decoder params:   8,653,638\n",
            "\n",
            "‚öôÔ∏è  Hyperparameters:\n",
            "  ‚Ä¢ Hidden size:         512\n",
            "  ‚Ä¢ Embedding dim:       256\n",
            "  ‚Ä¢ LSTM layers:         2\n",
            "  ‚Ä¢ Dropout:             0.3\n",
            "  ‚Ä¢ Teacher forcing:     0.5\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"K·∫æT H·ª¢P ENCODER-DECODER\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, src_lengths, trg, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.size(0)\n",
        "        trg_len = trg.size(1)\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size, device=self.device)\n",
        "\n",
        "        hidden, cell = self.encoder(src, src_lengths)\n",
        "\n",
        "        inp = trg[:, 0]\n",
        "        for t in range(1, trg_len):\n",
        "            out, hidden, cell = self.decoder(inp, hidden, cell)\n",
        "            outputs[:, t, :] = out\n",
        "\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = out.argmax(1)\n",
        "            inp = trg[:, t] if teacher_force else top1\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# --------------------------\n",
        "# Hyperparameters + init\n",
        "# --------------------------\n",
        "INPUT_DIM  = len(en_vocab)\n",
        "OUTPUT_DIM = len(fr_vocab)\n",
        "\n",
        "EMBEDDING_DIM = 256\n",
        "HIDDEN_DIM = 512\n",
        "N_LAYERS = 2\n",
        "DROPOUT = 0.3\n",
        "TEACHER_FORCING_RATIO = 0.5\n",
        "\n",
        "encoder = Encoder(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, N_LAYERS, DROPOUT)\n",
        "decoder = Decoder(OUTPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, N_LAYERS, DROPOUT)\n",
        "model = Seq2Seq(encoder, decoder, device).to(device)\n",
        "\n",
        "def count_parameters(m):\n",
        "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"‚úÖ Seq2Seq model initialized!\")\n",
        "print(f\"  ‚Ä¢ Total parameters: {count_parameters(model):,}\")\n",
        "print(f\"  ‚Ä¢ Encoder params:   {count_parameters(encoder):,}\")\n",
        "print(f\"  ‚Ä¢ Decoder params:   {count_parameters(decoder):,}\")\n",
        "\n",
        "print(f\"\\n‚öôÔ∏è  Hyperparameters:\")\n",
        "print(f\"  ‚Ä¢ Hidden size:         {HIDDEN_DIM}\")\n",
        "print(f\"  ‚Ä¢ Embedding dim:       {EMBEDDING_DIM}\")\n",
        "print(f\"  ‚Ä¢ LSTM layers:         {N_LAYERS}\")\n",
        "print(f\"  ‚Ä¢ Dropout:             {DROPOUT}\")\n",
        "print(f\"  ‚Ä¢ Teacher forcing:     {TEACHER_FORCING_RATIO}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKs-xsATMrDn"
      },
      "source": [
        "## 7. Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvB2Tuo9M0n7",
        "outputId": "e135d205-e474-4764-f92a-2bf967223009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ƒê·ªäNH NGHƒ®A TRAINING\n",
            "================================================================================\n",
            "‚úÖ Training functions ready!\n",
            "\n",
            "‚öôÔ∏è  Training Configuration:\n",
            "  ‚Ä¢ Loss:         CrossEntropyLoss(ignore_index=0)\n",
            "  ‚Ä¢ Optimizer:    Adam(lr=1e-3)\n",
            "  ‚Ä¢ Scheduler:    ReduceLROnPlateau(factor=0.5, patience=2)\n",
            "  ‚Ä¢ Gradient clip: 1.0\n",
            "  ‚Ä¢ Teacher forcing ratio (train): 0.5\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ƒê·ªäNH NGHƒ®A TRAINING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# NOTE: iterator ph·∫£i yield (src, src_lengths, trg) t·ª´ collate_fn\n",
        "\n",
        "def train_epoch(model, iterator, optimizer, criterion, clip, device, tf_ratio):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for src, src_lengths, trg in tqdm(iterator, desc=\"Training\", leave=False):\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, src_lengths, trg, teacher_forcing_ratio=tf_ratio)  # [B, T, V]\n",
        "        V = output.size(-1)\n",
        "\n",
        "        output = output[:, 1:, :].reshape(-1, V)  # b·ªè <sos>\n",
        "        trg    = trg[:, 1:].reshape(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, iterator, criterion, device):\n",
        "    model.eval()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for src, src_lengths, trg in tqdm(iterator, desc=\"Evaluating\", leave=False):\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "        output = model(src, src_lengths, trg, teacher_forcing_ratio=0)  # no TF\n",
        "        V = output.size(-1)\n",
        "\n",
        "        output = output[:, 1:, :].reshape(-1, V)\n",
        "        trg    = trg[:, 1:].reshape(-1)\n",
        "\n",
        "        epoch_loss += criterion(output, trg).item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Loss / Optimizer / Scheduler\n",
        "# ---------------------------\n",
        "PAD_IDX = fr_vocab.stoi[\"<pad>\"]                 # ignore PAD c·ªßa target (FR)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"min\", factor=0.5, patience=2\n",
        ")\n",
        "\n",
        "CLIP = 1.0\n",
        "\n",
        "print(\"‚úÖ Training functions ready!\")\n",
        "print(\"\\n‚öôÔ∏è  Training Configuration:\")\n",
        "print(f\"  ‚Ä¢ Loss:         CrossEntropyLoss(ignore_index={PAD_IDX})\")\n",
        "print(\"  ‚Ä¢ Optimizer:    Adam(lr=1e-3)\")\n",
        "print(\"  ‚Ä¢ Scheduler:    ReduceLROnPlateau(factor=0.5, patience=2)\")\n",
        "print(f\"  ‚Ä¢ Gradient clip: {CLIP}\")\n",
        "print(f\"  ‚Ä¢ Teacher forcing ratio (train): {TEACHER_FORCING_RATIO}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxf0GtpkNeIA"
      },
      "source": [
        "## 8. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Jv94s40NhJ3",
        "outputId": "d12911bf-b1ec-479a-ab39-1da217b73f2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "TRAINING\n",
            "================================================================================\n",
            "\n",
            "‚è∞ Training 20 epochs...\n",
            "üìä Early stopping patience: 3\n",
            "üéõÔ∏è  Teacher forcing (train): 0.5\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÖ Epoch: 01/20 | ‚è±Ô∏è  Time: 0m 41s\n",
            "   üìâ Train Loss: 1.616 | PPL:   5.033\n",
            "   üìâ Val Loss:   3.259 | PPL:  26.034\n",
            "   ‚úÖ Best model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÖ Epoch: 02/20 | ‚è±Ô∏è  Time: 0m 39s\n",
            "   üìâ Train Loss: 1.497 | PPL:   4.469\n",
            "   üìâ Val Loss:   3.270 | PPL:  26.319\n",
            "   ‚è≥ Patience: 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÖ Epoch: 03/20 | ‚è±Ô∏è  Time: 0m 40s\n",
            "   üìâ Train Loss: 1.430 | PPL:   4.177\n",
            "   üìâ Val Loss:   3.352 | PPL:  28.556\n",
            "   ‚è≥ Patience: 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                           "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÖ Epoch: 04/20 | ‚è±Ô∏è  Time: 0m 39s\n",
            "   üìâ Train Loss: 1.368 | PPL:   3.928\n",
            "   üìâ Val Loss:   3.325 | PPL:  27.790\n",
            "   ‚è≥ Patience: 3/3\n",
            "\n",
            "‚ö†Ô∏è  Early stopping at epoch 4\n",
            "\n",
            "================================================================================\n",
            "‚úÖ Training completed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "N_EPOCHS = 20\n",
        "PATIENCE = 3\n",
        "best_valid_loss = float(\"inf\")\n",
        "patience_counter = 0\n",
        "\n",
        "train_losses, val_losses = [], []\n",
        "\n",
        "print(f\"\\n‚è∞ Training {N_EPOCHS} epochs...\")\n",
        "print(f\"üìä Early stopping patience: {PATIENCE}\")\n",
        "print(f\"üéõÔ∏è  Teacher forcing (train): {TEACHER_FORCING_RATIO}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # IMPORTANT: train_epoch hi·ªán c·∫ßn tf_ratio\n",
        "    train_loss = train_epoch(\n",
        "        model, train_loader, optimizer, criterion,\n",
        "        clip=CLIP, device=device, tf_ratio=TEACHER_FORCING_RATIO\n",
        "    )\n",
        "\n",
        "    valid_loss = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = divmod(end_time - start_time, 60)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(valid_loss)\n",
        "\n",
        "    scheduler.step(valid_loss)\n",
        "\n",
        "    print(f\"\\nüìÖ Epoch: {epoch+1:02}/{N_EPOCHS} | ‚è±Ô∏è  Time: {int(epoch_mins)}m {int(epoch_secs)}s\")\n",
        "    print(f\"   üìâ Train Loss: {train_loss:.3f} | PPL: {math.exp(train_loss):7.3f}\")\n",
        "    print(f\"   üìâ Val Loss:   {valid_loss:.3f} | PPL: {math.exp(valid_loss):7.3f}\")\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        print(\"   ‚úÖ Best model saved!\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"   ‚è≥ Patience: {patience_counter}/{PATIENCE}\")\n",
        "\n",
        "    if patience_counter >= PATIENCE:\n",
        "        print(f\"\\n‚ö†Ô∏è  Early stopping at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ Training completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tES6j1A_Noem"
      },
      "source": [
        "## 9. V·∫Ω ƒë∆∞·ªùng training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "VhmVCSDGNsIg",
        "outputId": "e73b1372-43f4-4214-8df5-6eca4b6e9ba3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "T√ìM T·∫ÆT BEST EPOCH (THEO VAL LOSS)\n",
            "================================================================================\n",
            "‚úÖ Best epoch: 1/4\n",
            "  ‚Ä¢ Train Loss: 1.616 | Train PPL: 5.033\n",
            "  ‚Ä¢ Val   Loss: 3.259 | Val   PPL: 26.034\n",
            "\n",
            "================================================================================\n",
            "üìä B∆Ø·ªöC 9.2: V·∫º TH√äM ƒêI·ªÇM BEST EPOCH TR√äN BI·ªÇU ƒê·ªí\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved: training_curves_best_epoch.png\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"T√ìM T·∫ÆT BEST EPOCH (THEO VAL LOSS)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# train_losses, val_losses ƒë√£ c√≥ t·ª´ b∆∞·ªõc 8\n",
        "best_epoch = int(np.argmin(val_losses)) + 1\n",
        "best_train_loss = train_losses[best_epoch - 1]\n",
        "best_val_loss = val_losses[best_epoch - 1]\n",
        "\n",
        "print(f\"‚úÖ Best epoch: {best_epoch}/{len(val_losses)}\")\n",
        "print(f\"  ‚Ä¢ Train Loss: {best_train_loss:.3f} | Train PPL: {math.exp(best_train_loss):.3f}\")\n",
        "print(f\"  ‚Ä¢ Val   Loss: {best_val_loss:.3f} | Val   PPL: {math.exp(best_val_loss):.3f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä B∆Ø·ªöC 9.2: V·∫º TH√äM ƒêI·ªÇM BEST EPOCH TR√äN BI·ªÇU ƒê·ªí\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label=\"Train Loss\", marker=\"o\", linewidth=2)\n",
        "plt.plot(val_losses,   label=\"Val Loss\",   marker=\"s\", linewidth=2)\n",
        "plt.axvline(best_epoch - 1, linestyle=\"--\", linewidth=2, label=f\"Best epoch = {best_epoch}\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training & Validation Loss\", fontsize=14, fontweight=\"bold\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# PPL\n",
        "plt.subplot(1, 2, 2)\n",
        "train_ppl = [math.exp(x) for x in train_losses]\n",
        "val_ppl   = [math.exp(x) for x in val_losses]\n",
        "plt.plot(train_ppl, label=\"Train PPL\", marker=\"o\", linewidth=2)\n",
        "plt.plot(val_ppl,   label=\"Val PPL\",   marker=\"s\", linewidth=2)\n",
        "plt.axvline(best_epoch - 1, linestyle=\"--\", linewidth=2, label=f\"Best epoch = {best_epoch}\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Perplexity\")\n",
        "plt.title(\"Training & Validation Perplexity\", fontsize=14, fontweight=\"bold\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"training_curves_best_epoch.png\", dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Saved: training_curves_best_epoch.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvhNzgsoNwH9"
      },
      "source": [
        "## 10. ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reBm1OXsNytE",
        "outputId": "f9b373b7-ace6-420d-ae85-2544d38a4f4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ƒê√ÅNH GI√Å TR√äN TEST SET\n",
            "================================================================================\n",
            "‚úÖ Loaded best model from: best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                           "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üéØ Test Results:\n",
            "  ‚Ä¢ Test Loss: 3.184\n",
            "  ‚Ä¢ Test PPL:  24.140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ƒê√ÅNH GI√Å TR√äN TEST SET\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ---------------------------\n",
        "# 1Ô∏è‚É£ Load l·∫°i m√¥ h√¨nh t·ªët nh·∫•t\n",
        "# ---------------------------\n",
        "# ·ªû b∆∞·ªõc training (B∆∞·ªõc 8), m·ªói khi val_loss t·ªët h∆°n,\n",
        "# ta ƒë√£ l∆∞u tr·ªçng s·ªë m√¥ h√¨nh v√†o file 'best_model.pth'.\n",
        "# T·∫°i ƒë√¢y, ta load l·∫°i tr·ªçng s·ªë ƒë√≥ ƒë·ªÉ ƒë√°nh gi√° tr√™n test set.\n",
        "checkpoint_path = \"best_model.pth\"\n",
        "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "print(f\"‚úÖ Loaded best model from: {checkpoint_path}\")\n",
        "# ---------------------------\n",
        "# 2Ô∏è‚É£ ƒê√°nh gi√° tr√™n t·∫≠p test\n",
        "# ---------------------------\n",
        "# S·ª≠ d·ª•ng l·∫°i h√†m evaluate ƒë√£ ƒë·ªãnh nghƒ©a ·ªü B∆∞·ªõc 7.\n",
        "#   - Kh√¥ng d√πng teacher forcing (ratio=0)\n",
        "#   - Kh√¥ng t√≠nh gradient (trong h√†m evaluate ƒë√£ c√≥ torch.no_grad())\n",
        "test_loss = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "# ---------------------------\n",
        "# 3Ô∏è‚É£ In k·∫øt qu·∫£\n",
        "# ---------------------------\n",
        "print(f\"\\nüéØ Test Results:\")\n",
        "print(f\"  ‚Ä¢ Test Loss: {test_loss:.3f}\")\n",
        "print(f\"  ‚Ä¢ Test PPL:  {math.exp(test_loss):.3f}\")\n",
        "#   - Test Loss: cross-entropy trung b√¨nh tr√™n to√†n b·ªô t·∫≠p test\n",
        "#   - Test PPL (Perplexity): e^(loss), th∆∞·ªõc ƒëo m·ª©c ƒë·ªô \"b·ªëi r·ªëi\" c·ªßa m√¥ h√¨nh\n",
        "#       + PPL c√†ng th·∫•p ‚Üí m√¥ h√¨nh c√†ng d·ª± ƒëo√°n t·ªët chu·ªói token tr√™n test set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qewavTPHN6C2"
      },
      "source": [
        "## 11. H√†m d·ªãch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HG2PdqVKN9gg",
        "outputId": "e58eaed0-5266-4b47-fa06-1e7e985ded7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "INFERENCE - H√ÄM D·ªäCH\n",
            "================================================================================\n",
            "‚úÖ Translation functions defined!\n",
            "\n",
            "üåê Example Translations:\n",
            "================================================================================\n",
            "\n",
            "1. üá¨üáß EN: a man in a blue shirt is standing on a ladder cleaning a window .\n",
            "   üá´üá∑ FR: un homme en t - shirt bleu est debout sur une √©chelle pr√®s d' une fen√™tre .\n",
            "\n",
            "2. üá¨üáß EN: a little girl climbing into a wooden playhouse .\n",
            "   üá´üá∑ FR: une petite fille grimpe dans une maisonnette en bois .\n",
            "\n",
            "3. üá¨üáß EN: a dog running through the grass .\n",
            "   üá´üá∑ FR: un chien courant dans l' herbe .\n",
            "\n",
            "4. üá¨üáß EN: two young guys with shaggy hair look at their hands while hanging out in the yard .\n",
            "   üá´üá∑ FR: deux jeunes gars avec des cheveux gris regardent leurs mains dans leurs mains dans leurs mains .\n",
            "\n",
            "5. üá¨üáß EN: a child in a pink dress is climbing up a set of stairs in an entry way .\n",
            "   üá´üá∑ FR: un enfant en robe rose fait un escalier devant un parking .\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"INFERENCE - H√ÄM D·ªäCH\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def translate_sentence(model, sentence, src_vocab, trg_vocab, device, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    # 1) tokenize\n",
        "    tokens = tokenize_en(sentence) if isinstance(sentence, str) else sentence\n",
        "\n",
        "    # 2) numericalize\n",
        "    src_ids = src_vocab.numericalize(tokens)\n",
        "    if len(src_ids) == 0:\n",
        "        return []\n",
        "\n",
        "    src_tensor  = torch.LongTensor(src_ids).unsqueeze(0).to(device)   # [1, src_len]\n",
        "    src_lengths = torch.LongTensor([len(src_ids)]).to(device)         # [1]\n",
        "\n",
        "    trg_indexes = [trg_vocab.stoi[\"<sos>\"]]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.encoder(src_tensor, src_lengths)\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)  # [1]\n",
        "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
        "            pred_token = output.argmax(1).item()\n",
        "            trg_indexes.append(pred_token)\n",
        "\n",
        "            if pred_token == trg_vocab.stoi[\"<eos>\"]:\n",
        "                break\n",
        "\n",
        "    # id -> token, b·ªè <sos>, <eos>\n",
        "    trg_tokens = [trg_vocab.itos[i] for i in trg_indexes]\n",
        "    return trg_tokens[1:-1]\n",
        "\n",
        "@torch.no_grad()\n",
        "def translate(sentence: str, max_len: int = 50) -> str:\n",
        "    return \" \".join(translate_sentence(model, sentence, en_vocab, fr_vocab, device, max_len=max_len))\n",
        "\n",
        "print(\"‚úÖ Translation functions defined!\")\n",
        "\n",
        "print(\"\\nüåê Example Translations:\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "examples = [\n",
        "    \"a man in a blue shirt is standing on a ladder cleaning a window .\",\n",
        "    \"a little girl climbing into a wooden playhouse .\",\n",
        "    \"a dog running through the grass .\",\n",
        "    \"two young guys with shaggy hair look at their hands while hanging out in the yard .\",\n",
        "    \"a child in a pink dress is climbing up a set of stairs in an entry way .\"\n",
        "]\n",
        "\n",
        "for i, sent in enumerate(examples, 1):\n",
        "    print(f\"\\n{i}. üá¨üáß EN: {sent}\")\n",
        "    print(f\"   üá´üá∑ FR: {translate(sent)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xitl3HFODlD"
      },
      "source": [
        "## 12. T√≠nh BLEU SCORE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10nqyUhPOHnY",
        "outputId": "5a1dd02a-8c3e-476f-adf8-04535d216141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "T√çNH BLEU SCORE\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "üéØ EVALUATING ON TEST SET\n",
            "================================================================================\n",
            "\n",
            "üîÑ Translating 500 sentences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:03<00:00, 125.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Calculating BLEU scores (NLTK corpus_bleu)...\n",
            "\n",
            "üéØ BLEU Score: 35.99\n",
            "\n",
            "üìä Translation Statistics:\n",
            "  ‚Ä¢ Number of sentences: 500\n",
            "  ‚Ä¢ Average BLEU: 35.99\n",
            "\n",
            "üìè BLEU by Sentence Length:\n",
            "  ‚Ä¢ Short (<10 words):   43.30 (103 sentences)\n",
            "  ‚Ä¢ Medium (10-20):      33.68 (384 sentences)\n",
            "  ‚Ä¢ Long (>20 words):    17.62 (13 sentences)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"T√çNH BLEU SCORE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\n",
        "\n",
        "def calculate_bleu(data, src_vocab, trg_vocab, model, device, max_samples=None):\n",
        "    if max_samples is not None:\n",
        "        data = data[:max_samples]\n",
        "\n",
        "    targets, outputs = [], []\n",
        "    print(f\"\\nüîÑ Translating {len(data)} sentences...\")\n",
        "\n",
        "    for src, trg in tqdm(data, desc=\"Translating\"):\n",
        "        pred_trg = translate_sentence(model, src, src_vocab, trg_vocab, device)\n",
        "        targets.append([trg])     # corpus_bleu expects list-of-references\n",
        "        outputs.append(pred_trg)  # hypothesis\n",
        "\n",
        "    print(\"üìä Calculating BLEU scores (NLTK corpus_bleu)...\")\n",
        "    smooth = SmoothingFunction().method4\n",
        "    avg_bleu = corpus_bleu(targets, outputs, smoothing_function=smooth) * 100\n",
        "\n",
        "    return avg_bleu, outputs, targets\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üéØ EVALUATING ON TEST SET\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "test_data = list(zip(test_en, test_fr))\n",
        "bleu_score, predictions, references = calculate_bleu(\n",
        "    test_data, en_vocab, fr_vocab, model, device, max_samples=500\n",
        ")\n",
        "\n",
        "print(f\"\\nüéØ BLEU Score: {bleu_score:.2f}\")\n",
        "\n",
        "print(f\"\\nüìä Translation Statistics:\")\n",
        "print(f\"  ‚Ä¢ Number of sentences: {len(predictions)}\")\n",
        "print(f\"  ‚Ä¢ Average BLEU: {bleu_score:.2f}\")\n",
        "\n",
        "print(f\"\\nüìè BLEU by Sentence Length:\")\n",
        "short_bleu, medium_bleu, long_bleu = [], [], []\n",
        "\n",
        "smooth = SmoothingFunction().method4\n",
        "test_data_used = test_data[:len(predictions)]\n",
        "\n",
        "# DEBUG = False  # b·∫≠t n·∫øu c·∫ßn\n",
        "# if DEBUG:\n",
        "#     print(f\"DEBUG lens: test_data_used={len(test_data_used)}, preds={len(predictions)}, refs={len(references)}\")\n",
        "\n",
        "for (src_tokens, _), pred, ref in zip(test_data_used, predictions, references):\n",
        "    src_len = len(src_tokens)\n",
        "    bleu = sentence_bleu(ref, pred, smoothing_function=smooth) * 100\n",
        "\n",
        "    if src_len < 10:\n",
        "        short_bleu.append(bleu)\n",
        "    elif src_len <= 20:\n",
        "        medium_bleu.append(bleu)\n",
        "    else:\n",
        "        long_bleu.append(bleu)\n",
        "\n",
        "if short_bleu:\n",
        "    print(f\"  ‚Ä¢ Short (<10 words):   {sum(short_bleu)/len(short_bleu):.2f} ({len(short_bleu)} sentences)\")\n",
        "if medium_bleu:\n",
        "    print(f\"  ‚Ä¢ Medium (10-20):      {sum(medium_bleu)/len(medium_bleu):.2f} ({len(medium_bleu)} sentences)\")\n",
        "if long_bleu:\n",
        "    print(f\"  ‚Ä¢ Long (>20 words):    {sum(long_bleu)/len(long_bleu):.2f} ({len(long_bleu)} sentences)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB-pnjQrUwnR"
      },
      "source": [
        "## 13. SHOW EXAMPLE TRANSLATIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpIpsR88U1nH",
        "outputId": "aead0797-156c-4ca2-ebd7-89e693fbbc05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üåê EXAMPLE TRANSLATIONS\n",
            "================================================================================\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "üá¨üáß Source:    a young boy wearing white pants is jumping off the couch .\n",
            "üá´üá∑ Reference: un jeune gar√ßon v√™tu d' un pantalon blanc saute sur le canap√© .\n",
            "ü§ñ Predicted:  un jeune gar√ßon v√™tu d' un pantalon blanc saute par - dessus son canap√© .\n",
            "üìä Word Accuracy: 69.2% | Length: 15 vs 13 (+2)\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "üá¨üáß Source:    a child wearing a yellow shirt is jumping up and down .\n",
            "üá´üá∑ Reference: un enfant en maillot jaune saute .\n",
            "ü§ñ Predicted:  un enfant v√™tu d' un t - shirt jaune saute par - dessus .\n",
            "üìä Word Accuracy: 28.6% | Length: 14 vs 7 (+7)\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "üá¨üáß Source:    the dali lama during a reception where participants have brought carnations , parasols and prayer flags .\n",
            "üá´üá∑ Reference: le dala√Ø lama lors d' une r√©ception o√π les participants ont apport√© des ≈ìillets , des ombrelles et des drapeaux de pri√®re .\n",
            "ü§ñ Predicted:  le <unk> <unk> <unk> lors d' une comp√©tition de karat√© , et <unk> <unk> et <unk> <unk> et <unk> <unk> .\n",
            "üìä Word Accuracy: 8.7% | Length: 21 vs 23 (-2)\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "üá¨üáß Source:    a woman playing with two young boys at a park\n",
            "üá´üá∑ Reference: une femme jouant avec deux jeunes gar√ßons dans un parc\n",
            "ü§ñ Predicted:  une femme jouant de deux jeunes gar√ßons dans un parc\n",
            "üìä Word Accuracy: 90.0% | Length: 10 vs 10 (+0)\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "üá¨üáß Source:    two men wearing swim trunks jump in the air at a moderately populated beach .\n",
            "üá´üá∑ Reference: deux hommes portant des maillots de bain sautent en l' air sur une plage moyennement peupl√©e .\n",
            "ü§ñ Predicted:  deux hommes portant des maillots de bain sautent en l' air sur une plage de .\n",
            "üìä Word Accuracy: 82.4% | Length: 16 vs 17 (-1)\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "üá¨üáß Source:    a brown and white dog fetching a toy .\n",
            "üá´üá∑ Reference: un chien blanc et marron r√©cup√©rant un jouet .\n",
            "ü§ñ Predicted:  un chien marron et blanc rapportant un jouet .\n",
            "üìä Word Accuracy: 66.7% | Length: 9 vs 9 (+0)\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "üá¨üáß Source:    two female members of team usa performing a jump high - five surrounded by two other female members .\n",
            "üá´üá∑ Reference: deux femmes membres de l' √©quipe am√©ricaine sautant en se tapant dans les mains , entour√©es de deux autres co√©quipi√®res .\n",
            "ü§ñ Predicted:  deux √©quipe de femmes <unk> des <unk> une comp√©tition de softball s' appr√™te √† deux deux autres enfants .\n",
            "üìä Word Accuracy: 4.8% | Length: 19 vs 21 (-2)\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "üá¨üáß Source:    the man in the white t - shirt is starting to climb a rock .\n",
            "üá´üá∑ Reference: l' homme en t - shirt blanc commence √† escalader un rocher .\n",
            "ü§ñ Predicted:  l' homme en t - shirt blanc est en train de escalader un rocher .\n",
            "üìä Word Accuracy: 53.8% | Length: 15 vs 13 (+2)\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "üá¨üáß Source:    a man and a woman are sitting on the base of fence having a conversation .\n",
            "üá´üá∑ Reference: un homme et une femme sont assis au pied d' une grille , en train de discuter .\n",
            "ü§ñ Predicted:  un homme et une femme sont assis sur la plage , entretenant une photo .\n",
            "üìä Word Accuracy: 38.9% | Length: 15 vs 18 (-3)\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "üá¨üáß Source:    the young boy learns how to ride a bike with his dad .\n",
            "üá´üá∑ Reference: le jeune gar√ßon apprend √† faire du v√©lo avec son papa .\n",
            "ü§ñ Predicted:  le jeune gar√ßon fait comment prendre un coup avec son v√©lo avec son v√©lo .\n",
            "üìä Word Accuracy: 41.7% | Length: 15 vs 12 (+3)\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üåê EXAMPLE TRANSLATIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# L∆∞u √Ω:\n",
        "#   - ƒê·∫øn b∆∞·ªõc n√†y, b·∫°n ƒë√£ c√≥:\n",
        "#       + test_en      : danh s√°ch c√¢u ngu·ªìn (English), m·ªói c√¢u l√† list token\n",
        "#       + references   : list c√°c reference c√¢u ƒë√≠ch (French), d·∫°ng [[token1, token2, ...]]\n",
        "#       + predictions  : list c√°c c√¢u d·ªãch do m√¥ h√¨nh sinh ra (list token)\n",
        "#   - ƒê·∫£m b·∫£o ƒë√£ import random: import random\n",
        "\n",
        "# Ch·ªçn ng·∫´u nhi√™n m·ªôt s·ªë v√≠ d·ª• ƒë·ªÉ xem ch·∫•t l∆∞·ª£ng d·ªãch\n",
        "#   - random.sample: l·∫•y ng·∫´u nhi√™n k ph·∫ßn t·ª≠ kh√¥ng tr√πng t·ª´ range(len(predictions))\n",
        "#   - min(10, len(predictions)): n·∫øu c√¢u √≠t h∆°n 10 th√¨ ch·ªâ l·∫•y b·∫•y nhi√™u\n",
        "sample_indices = random.sample(range(len(predictions)), min(10, len(predictions)))\n",
        "\n",
        "# Duy·ªát qua t·ª´ng index ƒë∆∞·ª£c ch·ªçn\n",
        "for idx in sample_indices:\n",
        "    # C√¢u ngu·ªìn ti·∫øng Anh (list token)\n",
        "    src_sent = test_en[idx]\n",
        "    # C√¢u tham chi·∫øu ti·∫øng Ph√°p (list token), references[idx] l√† [ref_tokens]\n",
        "    ref_sent = references[idx][0]\n",
        "    # C√¢u m√¥ h√¨nh d·ªãch ra (list token)\n",
        "    pred_sent = predictions[idx]\n",
        "\n",
        "    print(f\"\\n{'‚îÄ'*80}\")\n",
        "    # Gh√©p list token th√†nh chu·ªói text b·∫±ng ' '.join(...)\n",
        "    print(f\"üá¨üáß Source:    {' '.join(src_sent)}\")\n",
        "    print(f\"üá´üá∑ Reference: {' '.join(ref_sent)}\")\n",
        "    print(f\"ü§ñ Predicted:  {' '.join(pred_sent)}\")\n",
        "\n",
        "    # T√≠nh \"word accuracy\" ƒë∆°n gi·∫£n:\n",
        "    #   - So s√°nh t·ª´ng c·∫∑p t·ª´ (pred, ref) t·∫°i c√πng v·ªã tr√≠\n",
        "    #   - ƒê·∫øm s·ªë t·ª´ tr√πng kh·ªõp\n",
        "    correct_words = sum(1 for p, r in zip(pred_sent, ref_sent) if p == r)\n",
        "    # Chia cho ƒë·ªô d√†i c√¢u tham chi·∫øu ƒë·ªÉ ra % (tr√°nh chia cho 0)\n",
        "    accuracy = correct_words / max(len(ref_sent), 1) * 100\n",
        "\n",
        "    # Ch√™nh l·ªách ƒë·ªô d√†i gi·ªØa c√¢u d·ª± ƒëo√°n v√† c√¢u tham chi·∫øu\n",
        "    len_diff = len(pred_sent) - len(ref_sent)\n",
        "\n",
        "    print(f\"üìä Word Accuracy: {accuracy:.1f}% | Length: {len(pred_sent)} vs {len(ref_sent)} ({len_diff:+d})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ƒê·ªãnh Nghƒ©a L·ªõp Attention"
      ],
      "metadata": {
        "id": "xMTHJt-_sKmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(hidden_dim * 2, hidden_dim)  # T√≠nh tr·ªçng s·ªë attention\n",
        "        self.v = nn.Parameter(torch.randn(hidden_dim))  # Tr·ªçng s·ªë v, kh·ªüi t·∫°o t·ª´ ph√¢n ph·ªëi chu·∫©n\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        hidden = hidden.squeeze(0)  # [batch_size, hidden_dim]\n",
        "        encoder_outputs = encoder_outputs  # [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        # T√≠nh ƒëi·ªÉm attention\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=1)))  # [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        # Chuy·ªÉn ƒë·ªïi self.v th√†nh tensor c√≥ k√≠ch th∆∞·ªõc [1, hidden_dim] ƒë·ªÉ ph√©p to√°n nh√¢n ma tr·∫≠n kh·ªõp\n",
        "        energy = energy.matmul(self.v.unsqueeze(0))  # [batch_size, src_len], th√™m chi·ªÅu cho v: [1, hidden_dim]\n",
        "\n",
        "        return torch.nn.functional.softmax(energy, dim=1).unsqueeze(1)  # Tr·∫£ v·ªÅ tr·ªçng s·ªë attention: [batch_size, 1, src_len]\n"
      ],
      "metadata": {
        "id": "6Edf5RFIskxm"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ƒê·ªãnh Nghƒ©a Decoder V·ªõi Attention"
      ],
      "metadata": {
        "id": "sBsEtmLSsXkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderWithAttention(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers, dropout, pad_idx=0):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=pad_idx)\n",
        "        self.lstm = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0, batch_first=True)\n",
        "        self.fc_out = nn.Linear(hidden_dim * 2, output_dim)  # Hidden state + Context vector\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.attention = Attention(hidden_dim)\n",
        "\n",
        "    def forward(self, input, hidden, cell, encoder_outputs):\n",
        "        input = input.unsqueeze(1)  # [B, 1]\n",
        "        embedded = self.dropout(self.embedding(input))  # [B, 1, emb_dim]\n",
        "\n",
        "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))  # [B, 1, hidden_dim]\n",
        "\n",
        "        # √Åp d·ª•ng Attention\n",
        "        attention_weights = self.attention(hidden, encoder_outputs)  # [B, 1, src_len]\n",
        "        context = attention_weights.bmm(encoder_outputs)  # [B, 1, hidden_dim]\n",
        "\n",
        "        # K·∫øt h·ª£p hidden state v·ªõi context vector\n",
        "        output = torch.cat((output.squeeze(1), context.squeeze(1)), dim=1)  # [B, hidden_dim * 2]\n",
        "        prediction = self.fc_out(output)  # [B, output_dim]\n",
        "\n",
        "        return prediction, hidden, cell\n"
      ],
      "metadata": {
        "id": "1WUSzmkzsomF"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ƒê·ªãnh Nghƒ©a M√¥ H√¨nh Seq2Seq V·ªõi Attention"
      ],
      "metadata": {
        "id": "aWUMmrUfsa8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqWithAttention(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, src_lengths, trg, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.size(0)\n",
        "        trg_len = trg.size(1)\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size, device=self.device)\n",
        "\n",
        "        # L·∫•y hidden v√† cell state t·ª´ encoder\n",
        "        hidden, cell = self.encoder(src, src_lengths)\n",
        "\n",
        "        # S·ª≠ d·ª•ng t·∫•t c·∫£ c√°c encoder outputs, kh√¥ng ch·ªâ hidden state cu·ªëi c√πng\n",
        "        encoder_outputs = hidden[0]  # [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        inp = trg[:, 0]  # S·ª≠ d·ª•ng <sos> token l√†m input ban ƒë·∫ßu\n",
        "        for t in range(1, trg_len):\n",
        "            # Pass input qua decoder\n",
        "            out, hidden, cell = self.decoder(inp, hidden, cell, encoder_outputs)\n",
        "            outputs[:, t, :] = out\n",
        "\n",
        "            # Quy·∫øt ƒë·ªãnh c√≥ s·ª≠ d·ª•ng teacher forcing hay kh√¥ng\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = out.argmax(1)\n",
        "            inp = trg[:, t] if teacher_force else top1\n",
        "\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "tCQZiSudsqL0"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hu·∫•n Luy·ªán M√¥ H√¨nh V·ªõi Attention"
      ],
      "metadata": {
        "id": "IW1BjPG7sdVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ƒê·∫£m b·∫£o m√¥ h√¨nh v√† d·ªØ li·ªáu ƒë·ªÅu tr√™n c√πng m·ªôt device (GPU ho·∫∑c CPU)\n",
        "attention_model = attention_model.to(device)\n",
        "\n",
        "train_losses, val_losses = [], []\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # ƒê·∫£m b·∫£o d·ªØ li·ªáu trong train_loader ƒë∆∞·ª£c chuy·ªÉn sang ƒë√∫ng device\n",
        "    train_loss = train_epoch(\n",
        "        attention_model, train_loader, optimizer, criterion, clip=CLIP, device=device, tf_ratio=TEACHER_FORCING_RATIO\n",
        "    )\n",
        "\n",
        "    valid_loss = evaluate(attention_model, val_loader, criterion, device)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = divmod(end_time - start_time, 60)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(valid_loss)\n",
        "\n",
        "    # ƒêi·ªÅu ch·ªânh learning rate sau m·ªói epoch\n",
        "    scheduler.step(valid_loss)\n",
        "\n",
        "    print(f\"\\nüìÖ Epoch: {epoch+1:02}/{N_EPOCHS} | ‚è±Ô∏è Time: {int(epoch_mins)}m {int(epoch_secs)}s\")\n",
        "    print(f\"   üìâ Train Loss: {train_loss:.3f} | PPL: {math.exp(train_loss):7.3f}\")\n",
        "    print(f\"   üìâ Val Loss:   {valid_loss:.3f} | PPL: {math.exp(valid_loss):7.3f}\")\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        patience_counter = 0\n",
        "        torch.save(attention_model.state_dict(), \"best_attention_model.pth\")\n",
        "        print(\"   ‚úÖ Best model saved!\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"   ‚è≥ Patience: {patience_counter}/{PATIENCE}\")\n",
        "\n",
        "    if patience_counter >= PATIENCE:\n",
        "        print(f\"\\n‚ö†Ô∏è Early stopping at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "    # In learning rate hi·ªán t·∫°i\n",
        "    print(f\"   üéõ Current learning rate: {optimizer.param_groups[0]['lr']:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "kFGLVQPiswfg",
        "outputId": "a23b2672-8696-426b-b757-935d6c162666"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Sizes of tensors must match except in dimension 1. Expected size 2 but got size 19 for tensor number 1 in the list.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-284836139.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# ƒê·∫£m b·∫£o d·ªØ li·ªáu trong train_loader ƒë∆∞·ª£c chuy·ªÉn sang ƒë√∫ng device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     train_loss = train_epoch(\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mattention_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCLIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTEACHER_FORCING_RATIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     )\n",
            "\u001b[0;32m/tmp/ipython-input-2318690111.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, iterator, optimizer, criterion, clip, device, tf_ratio)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf_ratio\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B, T, V]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2956304861.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_lengths, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3836436106.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, cell, encoder_outputs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# √Åp d·ª•ng Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B, 1, src_len]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B, 1, hidden_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4269514666.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# T√≠nh ƒëi·ªÉm attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0menergy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch_size, src_len, hidden_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0menergy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menergy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch_size, src_len]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 2 but got size 19 for tensor number 1 in the list."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## D·ªãch Th√†nh Qu·∫£ C·ªßa M√¥ H√¨nh V·ªõi Attention"
      ],
      "metadata": {
        "id": "XVinc-s7sfao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## So S√°nh BLEU Score Gi·ªØa Hai M√¥ H√¨nh"
      ],
      "metadata": {
        "id": "tyX3zHSpsh0K"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}